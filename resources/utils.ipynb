{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed6f1daf-9650-4618-9fd6-c362949f6dc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Note: we do not recommend to change the catalog here as it won't impact all the demo resources such as DLT pipeline and Dashboards.\n",
    "#Instead, please re-install the demo with a specific catalog and schema using dbdemos.install(\"lakehouse-retail-c360\", catalog=\"..\", schema=\"...\")\n",
    "\n",
    "catalog = \"wsdb_demos\"\n",
    "schema = dbName = db = \"agent_lab\"\n",
    "\n",
    "volume_name = \"hr_documents_volume\"\n",
    "VECTOR_SEARCH_ENDPOINT_NAME=\"agent_lab_endpoint\"\n",
    "\n",
    "MODEL_NAME = \"ai_rh_agent_demo\"\n",
    "ENDPOINT_NAME = f'{MODEL_NAME}_{catalog}_{db}'[:60]\n",
    "\n",
    "# This must be a tool-enabled model\n",
    "LLM_ENDPOINT_NAME = 'databricks-claude-3-7-sonnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fbd3011-0f5d-43d4-a07a-c4a398b930aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def endpoint_exists(vsc, vs_endpoint_name):\n",
    "  try:\n",
    "    return vs_endpoint_name in [e['name'] for e in vsc.list_endpoints().get('endpoints', [])]\n",
    "  except Exception as e:\n",
    "    #Temp fix for potential REQUEST_LIMIT_EXCEEDED issue\n",
    "    if \"REQUEST_LIMIT_EXCEEDED\" in str(e):\n",
    "      print(\"WARN: couldn't get endpoint status due to REQUEST_LIMIT_EXCEEDED error. The demo will consider it exists\")\n",
    "      return True\n",
    "    else:\n",
    "      raise e\n",
    "  \n",
    "def wait_for_vs_endpoint_to_be_ready(vsc, vs_endpoint_name):\n",
    "  for i in range(180):\n",
    "    try:\n",
    "      endpoint = vsc.get_endpoint(vs_endpoint_name)\n",
    "    except Exception as e:\n",
    "      #Temp fix for potential REQUEST_LIMIT_EXCEEDED issue\n",
    "      if \"REQUEST_LIMIT_EXCEEDED\" in str(e):\n",
    "        print(\"WARN: couldn't get endpoint status due to REQUEST_LIMIT_EXCEEDED error. Please manually check your endpoint status\")\n",
    "        return\n",
    "      else:\n",
    "        raise e\n",
    "    status = endpoint.get(\"endpoint_status\", endpoint.get(\"status\"))[\"state\"].upper()\n",
    "    if \"ONLINE\" in status:\n",
    "      return endpoint\n",
    "    elif \"PROVISIONING\" in status or i <6:\n",
    "      if i % 20 == 0: \n",
    "        print(f\"Waiting for endpoint to be ready, this can take a few min... {endpoint}\")\n",
    "      time.sleep(10)\n",
    "    else:\n",
    "      raise Exception(f'''Error with the endpoint {vs_endpoint_name}. - this shouldn't happen: {endpoint}.\\n Please delete it and re-run the previous cell: vsc.delete_endpoint(\"{vs_endpoint_name}\")''')\n",
    "  raise Exception(f\"Timeout, your endpoint isn't ready yet: {vsc.get_endpoint(vs_endpoint_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "814b901a-bd13-41e2-8977-cd85bf5ad846",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def index_exists(vsc, endpoint_name, index_full_name):\n",
    "    try:\n",
    "        vsc.get_index(endpoint_name, index_full_name).describe()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        if 'RESOURCE_DOES_NOT_EXIST' not in str(e):\n",
    "            print(f'Unexpected error describing the index. This could be a permission issue.')\n",
    "            raise e\n",
    "    return False\n",
    "    \n",
    "def wait_for_index_to_be_ready(vsc, vs_endpoint_name, index_name):\n",
    "  for i in range(180):\n",
    "    idx = vsc.get_index(vs_endpoint_name, index_name).describe()\n",
    "    index_status = idx.get('status', idx.get('index_status', {}))\n",
    "    status = index_status.get('detailed_state', index_status.get('status', 'UNKNOWN')).upper()\n",
    "    url = index_status.get('index_url', index_status.get('url', 'UNKNOWN'))\n",
    "    if \"ONLINE\" in status:\n",
    "      return\n",
    "    if \"UNKNOWN\" in status:\n",
    "      print(f\"Can't get the status - will assume index is ready {idx} - url: {url}\")\n",
    "      return\n",
    "    elif \"PROVISIONING\" in status:\n",
    "      if i % 40 == 0: print(f\"Waiting for index to be ready, this can take a few min... {index_status} - pipeline url:{url}\")\n",
    "      time.sleep(10)\n",
    "    else:\n",
    "        raise Exception(f'''Error with the index - this shouldn't happen. DLT pipeline might have been killed.\\n Please delete it and re-run the previous cell: vsc.delete_index(\"{index_name}, {vs_endpoint_name}\") \\nIndex details: {idx}''')\n",
    "  raise Exception(f\"Timeout, your index isn't ready yet: {vsc.get_index(index_name, vs_endpoint_name)}\")\n",
    "\n",
    "def wait_for_model_serving_endpoint_to_be_ready(ep_name):\n",
    "    from databricks.sdk import WorkspaceClient\n",
    "    from databricks.sdk.service.serving import EndpointStateReady, EndpointStateConfigUpdate\n",
    "    import time\n",
    "\n",
    "    # TODO make the endpoint name as a param\n",
    "    # Wait for it to be ready\n",
    "    w = WorkspaceClient()\n",
    "    state = \"\"\n",
    "    for i in range(200):\n",
    "        state = w.serving_endpoints.get(ep_name).state\n",
    "        if state.config_update == EndpointStateConfigUpdate.IN_PROGRESS:\n",
    "            if i % 40 == 0:\n",
    "                print(f\"Waiting for endpoint to deploy {ep_name}. Current state: {state}\")\n",
    "            time.sleep(10)\n",
    "        elif state.ready == EndpointStateReady.READY:\n",
    "          print('endpoint ready.')\n",
    "          return\n",
    "        else:\n",
    "          break\n",
    "    raise Exception(f\"Couldn't start the endpoint, timeout, please check your endpoint for more details: {state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ab7d403-f255-4599-8a9f-228784df6e5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#helper function defined to log the model and wrap\n",
    "def log_customer_support_agent_model(resources, request_example):\n",
    "    import mlflow\n",
    "    import mlflow.models\n",
    "    from mlflow.types.responses import ResponsesAgentRequest\n",
    "    model_config = mlflow.models.ModelConfig(development_config=\"../02_agent_eval/agent_config.yaml\")\n",
    "    with mlflow.start_run(run_name=model_config.get('config_version_name')):\n",
    "        return mlflow.pyfunc.log_model(\n",
    "            name=\"agent\",\n",
    "            python_model=\"../02_agent_eval/agent.py\",\n",
    "            model_config=\"../02_agent_eval/agent_config.yaml\",\n",
    "            input_example=ResponsesAgentRequest(input=[{\"role\": \"user\", \"content\": request_example}]),\n",
    "            resources=resources, # Determine Databricks resources (endpoints, fonctions, vs...) to specify for automatic auth passthrough at deployment time\n",
    "            extra_pip_requirements=[\"databricks-connect\"]\n",
    "        )\n",
    "\n",
    "def predict_wrapper(question):\n",
    "    # Format for chat-style models\n",
    "    model_input = pd.DataFrame({\n",
    "        \"input\": [[{\"role\": \"user\", \"content\": question}]]\n",
    "    })\n",
    "    response = loaded_model.predict(model_input)\n",
    "    return response['output'][-1]['content'][-1]['text']\n",
    "\n",
    "\n",
    "\n",
    "def get_scorers():\n",
    "    from mlflow.genai.scorers import RetrievalGroundedness, RelevanceToQuery, Safety, Guidelines\n",
    "    return [\n",
    "        RetrievalGroundedness(),  # Checks if email content is grounded in retrieved data\n",
    "        RelevanceToQuery(),  # Checks if email addresses the user's request\n",
    "        Safety(),  # Checks for harmful or inappropriate content\n",
    "        Guidelines(\n",
    "            guidelines=\"\"\"Reponse must be done without showing reaso\n",
    "            ning.\n",
    "            - don't mention that you need to look up things\n",
    "            - do not mention tools or function used\n",
    "            - do not tell your intermediate steps or reasoning\"\"\",\n",
    "            name=\"steps_and_reasoning\",\n",
    "        )\n",
    "    ]"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "utils",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
